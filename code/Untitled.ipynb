{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6019cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset, random_split\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import warnings\n",
    "torch.backends.cudnn.benchmark = True\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "844f824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiScaleConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiScaleConvNet, self).__init__()\n",
    "\n",
    "        # 第一层卷积，对原始序列进行卷积\n",
    "        self.conv1 = nn.Conv1d(in_channels=55, out_channels=64, kernel_size=1, padding=1)\n",
    "\n",
    "        # 第二层卷积，对不同尺度下的序列进行卷积\n",
    "        self.conv2_1 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2_3 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, padding=1)\n",
    "\n",
    "\n",
    "        # 池化层，将不同尺度下的特征进行池化\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=1)\n",
    "\n",
    "        self.gru = nn.GRU(input_size=64, hidden_size=32, bidirectional=True, batch_first=True)\n",
    "\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.flattten = nn.Flatten()\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "\n",
    "        # 全连接层，将不同尺度下的特征拼接在一起并进行分类\n",
    "        self.fc = nn.Linear(in_features=3232, out_features=512)\n",
    "        self.fc1 = nn.Linear(in_features=512, out_features=32)\n",
    "        self.fc2 = nn.Linear(in_features=32, out_features=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "        out1 = self.conv1(x)\n",
    "        out1 = self.pool(out1)\n",
    "        out1 = self.bn1(out1)  #128,64,34\n",
    "\n",
    "        # 第二层卷积\n",
    "        out2_1 = self.conv2_1(out1)\n",
    "        # print(out2_1.shape)\n",
    "        out2_2 = self.conv2_2(out1)\n",
    "        # print(out2_2.shape)\n",
    "        out2_3 = self.conv2_3(out1)\n",
    "        # print(out2_3.shape)\n",
    "\n",
    "        # 对不同尺度下的特征进行池化\n",
    "        out2_1 = self.pool(out2_1)\n",
    "        # print(out2_1.shape)\n",
    "        out2_2 = self.pool(out2_2)\n",
    "        # print(out2_1.shape)\n",
    "        out2_3 = self.pool(out2_3)\n",
    "        # print(out2_1.shape)\n",
    "\n",
    "\n",
    "        out2_1 = self.bn2(out2_1)\n",
    "        # print(out2_1.shape)\n",
    "        out2_2 = self.bn2(out2_2)\n",
    "        # print(out2_1.shape)\n",
    "        out2_3 = self.bn2(out2_3)\n",
    "        # print(out2_1.shape)\n",
    "\n",
    "        out2_1 = self.drop(out2_1)\n",
    "        # print(out2_1.shape)\n",
    "        out2_2 = self.drop(out2_2)\n",
    "        # print(out2_1.shape)\n",
    "        out2_3 = self.drop(out2_3)\n",
    "        # print(out2_1.shape)\n",
    "\n",
    "        gate_out1 = self.sig(out2_1)\n",
    "        gate_out2 = self.sig(out2_2)\n",
    "        gate_out3 = self.sig(out2_3)\n",
    "\n",
    "        gate_out1 =gate_out1*(1-gate_out2)*gate_out3# 32,32,33\n",
    "        att_output = self.flattten(gate_out1)\n",
    "        # att_output = self.ln1(att_output)\n",
    "\n",
    "        out1 = out1.transpose(dim0=1, dim1=2)\n",
    "        out1, (_, _) = self.gru(out1)  #\n",
    "        out1 = self.flattten(out1)\n",
    "        # out1 = self.ln2(out1)\n",
    "\n",
    "        # 将不同尺度下的特征进行分类\n",
    "        out = torch.concat([out1, att_output], dim=1)\n",
    "        out = self.fc(out)\n",
    "        out = self.fc1(out)\n",
    "        # out = self.drop(out)\n",
    "        out = self.fc2(out)\n",
    "        # out = self.drop(out)\n",
    "        out = self.sig(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b940e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"加载数据\n",
    "    单条格式：(文本, 标签id)\n",
    "    \"\"\"\n",
    "    D = []\n",
    "    seq = []\n",
    "    labels = []\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        for l in f:\n",
    "            text, label = l.strip().split(' ')\n",
    "            text = text.replace(\"'\", \"\")\n",
    "            label = label.replace(\"'\", \"\")\n",
    "            label = int(label)\n",
    "            D.append((text, label))\n",
    "            seq.append(text)\n",
    "            labels.append(label)\n",
    "    return D, seq, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3c366c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encoding(seqs):\n",
    "    # 确定蛋白质序列的长度，保存到一个变量中\n",
    "    seq_length = len(seqs[0])\n",
    "    # 初始化一个二维数组，行数为蛋白质序列的长度，列数为编码维度，每个元素都为0\n",
    "    one_hot = np.zeros((seq_length, 20))\n",
    "    # 遍历每个氨基酸序列，根据其在氨基酸表中的位置，在对应的列上将值设为1\n",
    "    aa_table = {'A': 0, 'R': 1, 'N': 2, 'D': 3, 'C': 4, 'Q': 5, 'E': 6, 'G': 7, 'H': 8, 'I': 9,\n",
    "                'L': 10, 'K': 11, 'M': 12, 'F': 13, 'P': 14, 'S': 15, 'T': 16, 'W': 17, 'Y': 18, 'V': 19}\n",
    "    encoded_sequences = []\n",
    "    for seq in seqs:\n",
    "        for i, aa in enumerate(seq):\n",
    "            one_hot[i, aa_table[aa]] = 1\n",
    "        encoded_sequences.append(one_hot)\n",
    "        one_hot = np.zeros((seq_length, 20))\n",
    "    # 将编码后的二维数组保存到一个列表中，依次存储所有蛋白质序列的编码\n",
    "    encoded_sequences = np.array(encoded_sequences)\n",
    "    return encoded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3095c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_encoding(filename, encoding_size):\n",
    "    with open(filename, encoding='utf-8') as f_in:\n",
    "        lines = f_in.readlines()\n",
    "    data = []\n",
    "    labels = []\n",
    "    for line in lines:\n",
    "        nums = [float(num) for num in line.strip().split(',')]\n",
    "        data_nums = np.array(nums[1:]).reshape(33, encoding_size)\n",
    "        data.append(data_nums)\n",
    "        label_nums = nums[0]\n",
    "        labels.append(label_nums)\n",
    "\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c0d0100",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'shap' has no attribute 'DeepExplainer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Windows\\Temp\\ipykernel_3488\\3197711741.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../best_model/580.8505859375.pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mexplainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDeepExplainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0monehot_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mshap_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexplainer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0monehot_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'shap' has no attribute 'DeepExplainer'"
     ]
    }
   ],
   "source": [
    "all_data, seq, label = load_data('../datasets/ST_1.csv')\n",
    "onehot_out = onehot_encoding(seq)\n",
    "\n",
    "blo_out, label = load_and_encoding(\"../feature/BLOSUM62/data_ST.csv\", 20)\n",
    "zscale_out, label = load_and_encoding('../feature/ZScale/data_ST.csv', 5)\n",
    "bin51_out, label = load_and_encoding('../feature/binary/data_ST_51.csv', 5)\n",
    "bin52_out, label = load_and_encoding('../feature/binary/data_ST_52.csv', 5)\n",
    "\n",
    "onehot_out = torch.from_numpy(onehot_out)\n",
    "blo_out = torch.from_numpy(blo_out)\n",
    "zscale_out = torch.from_numpy(zscale_out)\n",
    "bin51_out = torch.from_numpy(bin51_out)\n",
    "bin52_out = torch.from_numpy(bin52_out)\n",
    "label = torch.from_numpy(label)\n",
    "\n",
    "\n",
    "model = torch.load('../best_model/580.8505859375.pth')\n",
    "\n",
    "explainer = shap.DeepExplainer(model,onehot_out)\n",
    "shap_values = explainer.shap_values(explainer)\n",
    "shap.image_plot(shap_values,onehot_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f944b09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deepro",
   "language": "python",
   "name": "deepro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
